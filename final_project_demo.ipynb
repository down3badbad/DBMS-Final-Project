{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7506919b",
   "metadata": {},
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b84d4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio.windows_events import NULL\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "import PIL as Image\n",
    "import sqlalchemy as sql\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from model import run_simclr\n",
    "\n",
    "image_path = 'C:/Database_lec/VOCdevkit/VOC2012/'\n",
    "cropped_path = image_path + 'CropImagesReturn'\n",
    "test_img_path = 'C:/Database_lec/Final/test_image'\n",
    "similar_path = image_path + 'CropImagesSimilar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091087fc",
   "metadata": {},
   "source": [
    "# Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f16aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_engine = sql.create_engine(\"mysql+mysqlconnector://root:test@127.0.0.1:9527/db_image_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b703231",
   "metadata": {},
   "source": [
    "# Crop Function and Similarity Compute Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9740706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropping(cursor, cls_name):\n",
    "    query = f'select image_path, bbox_name, xmin, ymin, xmax, ymax \\\n",
    "            from images as I, bboxes as B \\\n",
    "            where B.class=\"{cls_name}\" \\\n",
    "            and I.image_id=B.image_id'\n",
    "    \n",
    "    result = cursor.execute(query)\n",
    "    print('Finish sql query!')\n",
    "\n",
    "    os.chmod(cropped_path, 755)\n",
    "    print('Start cropping image...')\n",
    "    for idx, row in enumerate(result):\n",
    "        img_path, bbox_name, xmin, ymin, xmax, ymax = row\n",
    "        \n",
    "        result_img = crop_image(img_path, xmin, ymin, xmax, ymax)\n",
    "        result_img.save(os.path.join(cropped_path, '%s.jpg' % (bbox_name)))\n",
    "\n",
    "def similarity(cursor, input_blob, cls_name, threshold):\n",
    "    # blob to image and save to temp folder\n",
    "    temp_path = image_path + 'TempImages'\n",
    "    with open(temp_path + '/temp.jpg', 'wb') as file:\n",
    "        file.write(input_blob)\n",
    "    \n",
    "    # get embedding of input image\n",
    "    img = Image.open(temp_path + '/temp.jpg').convert('RGB')\n",
    "    img_embd = run_simclr(img)\n",
    "    img_embd_encode = embedEncode(img_embd)\n",
    "\n",
    "    # create dataframe and send encoded embedding to db\n",
    "    embd_list= []\n",
    "    embd_list.append(img_embd_encode)\n",
    "    embed_dict = {'index': 0, 'embed': embd_list}\n",
    "    df_embed = pd.DataFrame(embed_dict)\n",
    "\n",
    "    # write it out to database\n",
    "    df_embed.to_sql('temp_img', cursor, if_exists='replace', index=False)\n",
    "\n",
    "    compete_query = f'select image_path, bbox_name, xmin, ymin, xmax, ymax \\\n",
    "                    from images as I, bboxes as B \\\n",
    "                    where B.bbox_id IN (SELECT bbox_id \\\n",
    "                    FROM embedding as E, temp_img as T \\\n",
    "                    WHERE embed_dist(E.embed, T.embed)<={threshold}) \\\n",
    "                    and I.image_id=B.image_id and B.class=\"{cls_name}\";'\n",
    "\n",
    "    result = cursor.execute(compete_query)\n",
    "    print('Finish sql query!')\n",
    "\n",
    "    os.chmod(similar_path, 755)\n",
    "    print('Start cropping image...')\n",
    "    for idx, row in enumerate(result):\n",
    "        print(row)\n",
    "        img_path, bbox_name, xmin, ymin, xmax, ymax = row\n",
    "        \n",
    "        result_img = crop_image(img_path, xmin, ymin, xmax, ymax)\n",
    "        result_img.save(os.path.join(similar_path, '%s.jpg' % (bbox_name)))\n",
    "        \n",
    "    drop_query = 'drop table if exists temp_img;'\n",
    "    cursor.execute(drop_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fa2bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cls = 'tvmonitor'\n",
    "threshold = 0.7\n",
    "testImagePath = test_img_path + '/2007_000187_32.jpg'\n",
    "with open(testImagePath, 'rb') as file: # image to blob\n",
    "    img_blob = file.read()\n",
    "\n",
    "query = f'select crop(\"{input_cls}\") from bboxes as B where B.class=\"{input_cls}\";'\n",
    "# select crop(\"tvmonitor\") from bboxes as B where B.class=\"tvmonitor\"\n",
    "\n",
    "\n",
    "query2 = f'select crop(\"{input_cls}\") from bboxes as B \\\n",
    "           where B.class=\"{input_cls}\" and similar(\"{img_blob}\", \"{input_cls}\")<={threshold};'\n",
    "# select crop(\"tvmonitor\") from bboxes as B where B.class=\"tvmonitor\" and similar(img_blob, \"tvmonitor\")<=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4aadb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish sql query!\n",
      "Start cropping image...\n"
     ]
    }
   ],
   "source": [
    "cropping(sql_engine, input_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "996211a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Finish sql query!\n",
      "Start cropping image...\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2007_000187.jpg', '2007_000187_32', 1, 95, 240, 336)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2007_001149.jpg', '2007_001149_186', 75, 85, 146, 153)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2007_001175.jpg', '2007_001175_192', 360, 114, 449, 187)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2007_007849.jpg', '2007_007849_1554', 100, 235, 134, 281)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2008_003825.jpg', '2008_003825_7441', 1, 345, 269, 417)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2008_005445.jpg', '2008_005445_9760', 58, 149, 147, 248)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2008_005976.jpg', '2008_005976_10494', 26, 25, 496, 321)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2008_007828.jpg', '2008_007828_13256', 434, 187, 500, 296)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2009_000398.jpg', '2009_000398_15194', 89, 338, 275, 500)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2009_000722.jpg', '2009_000722_15599', 125, 186, 178, 232)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2009_002110.jpg', '2009_002110_17328', 1, 1, 258, 375)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2009_003695.jpg', '2009_003695_19436', 383, 214, 444, 281)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2009_004062.jpg', '2009_004062_19897', 1, 138, 52, 198)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2009_004243.jpg', '2009_004243_20233', 153, 141, 192, 167)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2009_004359.jpg', '2009_004359_20372', 309, 14, 500, 253)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2009_005042.jpg', '2009_005042_21203', 350, 24, 500, 162)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2010_000318.jpg', '2010_000318_21872', 336, 64, 500, 249)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2010_000705.jpg', '2010_000705_22340', 115, 190, 202, 250)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2010_000787.jpg', '2010_000787_22447', 342, 156, 461, 306)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2010_004503.jpg', '2010_004503_26808', 17, 40, 324, 263)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2010_005827.jpg', '2010_005827_28372', 1, 1, 500, 286)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2011_000036.jpg', '2011_000036_29365', 130, 90, 285, 230)\n",
      "('C:/Database_lec/VOCdevkit/VOC2012\\\\JPEGImages\\\\2011_000399.jpg', '2011_000399_29877', 353, 114, 443, 190)\n"
     ]
    }
   ],
   "source": [
    "similarity(sql_engine, img_blob, input_cls, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559c9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
